{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IOI Circuit Replication Validation\n",
    "\n",
    "**End-to-End Validation Against \"Interpretability in the Wild\" (Wang et al. 2022)**\n",
    "\n",
    "This notebook validates our implementation of the Indirect Object Identification (IOI) circuit discovery against the original paper's findings.\n",
    "\n",
    "## Paper Reference\n",
    "Wang, K., et al. (2022). Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small. *ICLR 2023*.\n",
    "\n",
    "## Implementation Reference\n",
    "ARENA 1.4.1: Indirect Object Identification\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import torch\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import our modules\n",
    "from src.data.dataset import generate_ioi_dataset, load_ioi_dataset\n",
    "from src.model.model_loader import load_ioi_model\n",
    "from src.analysis.ioi_baseline import run_baseline, compute_logit_diff\n",
    "from src.analysis.activation_patching import (\n",
    "    patch_all_layers,\n",
    "    patch_all_heads,\n",
    "    analyze_example_patching\n",
    ")\n",
    "from src.analysis.attention_analysis import (\n",
    "    find_all_ioi_heads,\n",
    "    analyze_duplicate_token_attention,\n",
    "    analyze_s_inhibition_attention,\n",
    "    analyze_name_mover_attention\n",
    ")\n",
    "from src.analysis.path_patching import analyze_ioi_circuit_paths\n",
    "from src.analysis.circuit_discovery import (\n",
    "    discover_ioi_circuit,\n",
    "    validate_circuit,\n",
    "    print_circuit_summary\n",
    ")\n",
    "from src.analysis.logit_attribution import (\n",
    "    compare_io_vs_s_attribution,\n",
    "    plot_logit_attribution,\n",
    "    analyze_circuit_with_dla\n",
    ")\n",
    "\n",
    "# Plotting configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ“ Imports successful\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Results from Original Paper\n",
    "\n",
    "### Key Findings to Validate:\n",
    "\n",
    "1. **Baseline Performance**\n",
    "   - Model accuracy on IOI task: ~95% (paper reports high accuracy)\n",
    "   - Logit difference (IO - S): Positive and substantial (typically 5-10)\n",
    "\n",
    "2. **Circuit Components** (from paper Fig 2 & 3)\n",
    "   - **Duplicate Token Heads** (early layers 0-3): L0H1, L2H2, L3H0, etc.\n",
    "   - **S-Inhibition Heads** (middle layers 7-8): L7H3, L7H9, L8H6, L8H10\n",
    "   - **Name Mover Heads** (late layers 9-11): L9H6, L9H9, L10H0, L10H2, L11H10\n",
    "\n",
    "3. **Activation Patching Effects**\n",
    "   - Name mover heads: High positive effect (>0.5)\n",
    "   - S-inhibition heads: Moderate positive effect (0.2-0.5)\n",
    "   - Duplicate token heads: Low-moderate effect (0.1-0.3)\n",
    "\n",
    "4. **Path Patching**\n",
    "   - Strong paths: Duplicate â†’ S-inhibition\n",
    "   - Strong paths: S-inhibition â†’ Name mover\n",
    "   - Some direct paths: Duplicate â†’ Name mover\n",
    "\n",
    "5. **Direct Logit Attribution**\n",
    "   - Circuit heads account for 80-95% of logit difference\n",
    "   - Name movers: Large positive contribution to IO token\n",
    "   - S-inhibition: Large negative contribution to S token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 1: Data Generation and Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PHASE 1: DATA GENERATION AND MODEL LOADING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Generate datasets\n",
    "print(\"\\n1. Generating ABBA dataset (clean prompts)...\")\n",
    "generate_ioi_dataset(n_examples=500, template=\"ABBA\", seed=42)\n",
    "abba_dataset = load_ioi_dataset(\"../data/ioi_abba.json\")\n",
    "print(f\"   Generated {len(abba_dataset)} ABBA examples\")\n",
    "\n",
    "print(\"\\n2. Generating ABC dataset (corrupted prompts)...\")\n",
    "generate_ioi_dataset(n_examples=500, template=\"ABC\", seed=42)\n",
    "abc_dataset = load_ioi_dataset(\"../data/ioi_abc.json\")\n",
    "print(f\"   Generated {len(abc_dataset)} ABC examples\")\n",
    "\n",
    "# Load model\n",
    "print(\"\\n3. Loading GPT-2 Small with TransformerLens...\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "result = load_ioi_model(device=device)\n",
    "model = result[\"model\"]\n",
    "config = result[\"config\"]\n",
    "\n",
    "print(f\"   Model: {config['model_name']}\")\n",
    "print(f\"   Layers: {config['n_layers']}\")\n",
    "print(f\"   Heads: {config['n_heads']}\")\n",
    "print(f\"   Device: {config['device']}\")\n",
    "\n",
    "print(\"\\nâœ“ Phase 1 complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 2: Baseline Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PHASE 2: BASELINE PERFORMANCE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Run baseline on sample\n",
    "print(\"\\nRunning baseline analysis on 100 examples...\")\n",
    "baseline_results = run_baseline(\n",
    "    model,\n",
    "    \"../data/ioi_abba.json\",\n",
    "    max_examples=100\n",
    ")\n",
    "\n",
    "# Extract metrics\n",
    "accuracy = baseline_results[\"accuracy\"]\n",
    "mean_logit_diff = baseline_results[\"mean_logit_diff\"]\n",
    "std_logit_diff = baseline_results[\"std_logit_diff\"]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BASELINE RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Accuracy: {accuracy:.1%}\")\n",
    "print(f\"Mean Logit Diff (IO - S): {mean_logit_diff:.3f} Â± {std_logit_diff:.3f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Validation against paper\n",
    "validation_report = []\n",
    "\n",
    "print(\"\\nðŸ“Š VALIDATION CHECK 1: Baseline Performance\")\n",
    "if accuracy >= 0.90:\n",
    "    print(f\"   âœ“ PASS: Accuracy {accuracy:.1%} >= 90% (paper expects ~95%)\")\n",
    "    validation_report.append({\"test\": \"Baseline Accuracy\", \"status\": \"PASS\", \"value\": f\"{accuracy:.1%}\"})\n",
    "else:\n",
    "    print(f\"   âœ— FAIL: Accuracy {accuracy:.1%} < 90%\")\n",
    "    validation_report.append({\"test\": \"Baseline Accuracy\", \"status\": \"FAIL\", \"value\": f\"{accuracy:.1%}\"})\n",
    "\n",
    "if mean_logit_diff >= 3.0:\n",
    "    print(f\"   âœ“ PASS: Mean logit diff {mean_logit_diff:.3f} >= 3.0\")\n",
    "    validation_report.append({\"test\": \"Logit Difference\", \"status\": \"PASS\", \"value\": f\"{mean_logit_diff:.3f}\"})\n",
    "else:\n",
    "    print(f\"   âœ— FAIL: Mean logit diff {mean_logit_diff:.3f} < 3.0\")\n",
    "    validation_report.append({\"test\": \"Logit Difference\", \"status\": \"FAIL\", \"value\": f\"{mean_logit_diff:.3f}\"})\n",
    "\n",
    "print(\"\\nâœ“ Phase 2 complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 3: Activation Patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PHASE 3: ACTIVATION PATCHING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Use first example for detailed analysis\n",
    "example = abba_dataset[0]\n",
    "clean_prompt = example[\"prompt\"]\n",
    "print(f\"\\nClean prompt: {clean_prompt}\")\n",
    "\n",
    "# Create corrupted version\n",
    "corrupted_prompt = clean_prompt.replace(\n",
    "    f\", {example['io_name']} gave\",\n",
    "    f\", {example['s_name']} gave\"\n",
    ")\n",
    "print(f\"Corrupted prompt: {corrupted_prompt}\")\n",
    "\n",
    "clean_tokens = model.to_tokens(clean_prompt)\n",
    "corrupted_tokens = model.to_tokens(corrupted_prompt)\n",
    "\n",
    "io_token_id = model.to_single_token(\" \" + example[\"io_name\"])\n",
    "s_token_id = model.to_single_token(\" \" + example[\"s_name\"])\n",
    "\n",
    "# Patch all layers\n",
    "print(\"\\n1. Patching residual stream at all layers...\")\n",
    "layer_effects = patch_all_layers(\n",
    "    model, clean_tokens, corrupted_tokens,\n",
    "    io_token_id, s_token_id\n",
    ")\n",
    "\n",
    "# Plot layer effects\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(range(len(layer_effects)), layer_effects, marker='o')\n",
    "plt.xlabel('Layer')\n",
    "plt.ylabel('Patching Effect')\n",
    "plt.title('Activation Patching by Layer\\n(Effect of restoring clean activations)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.5, label='High Effect (>0.5)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/activation_patching_layers.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTop 3 most important layers:\")\n",
    "top_layers = sorted(enumerate(layer_effects), key=lambda x: x[1], reverse=True)[:3]\n",
    "for layer, effect in top_layers:\n",
    "    print(f\"   Layer {layer}: {effect:.3f}\")\n",
    "\n",
    "# Patch all heads\n",
    "print(\"\\n2. Patching all attention heads...\")\n",
    "head_effects = patch_all_heads(\n",
    "    model, clean_tokens, corrupted_tokens,\n",
    "    io_token_id, s_token_id\n",
    ")\n",
    "\n",
    "# Reshape for heatmap\n",
    "n_layers = model.cfg.n_layers\n",
    "n_heads = model.cfg.n_heads\n",
    "head_matrix = np.zeros((n_layers, n_heads))\n",
    "for (layer, head), effect in head_effects.items():\n",
    "    head_matrix[layer, head] = effect\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(\n",
    "    head_matrix,\n",
    "    cmap='RdYlGn',\n",
    "    center=0,\n",
    "    vmin=-0.2,\n",
    "    vmax=1.0,\n",
    "    cbar_kws={'label': 'Patching Effect'},\n",
    "    xticklabels=range(n_heads),\n",
    "    yticklabels=range(n_layers)\n",
    ")\n",
    "plt.xlabel('Head')\n",
    "plt.ylabel('Layer')\n",
    "plt.title('Activation Patching by Head\\n(Higher = More Important for IOI Task)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/activation_patching_heads.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Find top heads\n",
    "print(f\"\\nTop 10 most important heads:\")\n",
    "top_heads = sorted(head_effects.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "for (layer, head), effect in top_heads:\n",
    "    print(f\"   L{layer}H{head}: {effect:.3f}\")\n",
    "\n",
    "print(\"\\nâœ“ Phase 3 complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 4: Attention Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PHASE 4: ATTENTION PATTERN ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find all IOI heads using attention patterns\n",
    "print(\"\\nFinding IOI circuit heads using attention patterns...\")\n",
    "print(\"(Using 50 examples for robustness)\\n\")\n",
    "\n",
    "ioi_heads = find_all_ioi_heads(\n",
    "    model,\n",
    "    \"../data/ioi_abba.json\",\n",
    "    max_examples=50,\n",
    "    dup_threshold=0.4,\n",
    "    s_inhibition_threshold=0.3,\n",
    "    name_mover_threshold=0.3\n",
    ")\n",
    "\n",
    "duplicate_heads = ioi_heads[\"duplicate_token_heads\"]\n",
    "s_inhibition_heads = ioi_heads[\"s_inhibition_heads\"]\n",
    "name_mover_heads = ioi_heads[\"name_mover_heads\"]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DISCOVERED CIRCUIT HEADS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDuplicate Token Heads ({len(duplicate_heads)}):\")\n",
    "for layer, head in sorted(duplicate_heads):\n",
    "    print(f\"   L{layer}H{head}\")\n",
    "\n",
    "print(f\"\\nS-Inhibition Heads ({len(s_inhibition_heads)}):\")\n",
    "for layer, head in sorted(s_inhibition_heads):\n",
    "    print(f\"   L{layer}H{head}\")\n",
    "\n",
    "print(f\"\\nName Mover Heads ({len(name_mover_heads)}):\")\n",
    "for layer, head in sorted(name_mover_heads):\n",
    "    print(f\"   L{layer}H{head}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Compare with paper's reported heads\n",
    "paper_name_movers = [(9, 6), (9, 9), (10, 0), (10, 2)]\n",
    "paper_s_inhibition = [(7, 3), (7, 9), (8, 6), (8, 10)]\n",
    "\n",
    "print(\"\\nðŸ“Š VALIDATION CHECK 2: Circuit Head Discovery\")\n",
    "\n",
    "# Check name movers\n",
    "nm_overlap = len(set(name_mover_heads) & set(paper_name_movers))\n",
    "print(f\"\\nName Mover Heads:\")\n",
    "print(f\"   Paper reports: {paper_name_movers}\")\n",
    "print(f\"   We found: {sorted(name_mover_heads)}\")\n",
    "print(f\"   Overlap: {nm_overlap}/{len(paper_name_movers)}\")\n",
    "if nm_overlap >= 2:\n",
    "    print(f\"   âœ“ PASS: Found {nm_overlap} of paper's key name movers\")\n",
    "    validation_report.append({\"test\": \"Name Mover Discovery\", \"status\": \"PASS\", \"value\": f\"{nm_overlap}/{len(paper_name_movers)}\"})\n",
    "else:\n",
    "    print(f\"   âœ— FAIL: Only found {nm_overlap} of paper's key name movers\")\n",
    "    validation_report.append({\"test\": \"Name Mover Discovery\", \"status\": \"FAIL\", \"value\": f\"{nm_overlap}/{len(paper_name_movers)}\"})\n",
    "\n",
    "# Check S-inhibition\n",
    "si_overlap = len(set(s_inhibition_heads) & set(paper_s_inhibition))\n",
    "print(f\"\\nS-Inhibition Heads:\")\n",
    "print(f\"   Paper reports: {paper_s_inhibition}\")\n",
    "print(f\"   We found: {sorted(s_inhibition_heads)}\")\n",
    "print(f\"   Overlap: {si_overlap}/{len(paper_s_inhibition)}\")\n",
    "if si_overlap >= 2:\n",
    "    print(f\"   âœ“ PASS: Found {si_overlap} of paper's key S-inhibition heads\")\n",
    "    validation_report.append({\"test\": \"S-Inhibition Discovery\", \"status\": \"PASS\", \"value\": f\"{si_overlap}/{len(paper_s_inhibition)}\"})\n",
    "else:\n",
    "    print(f\"   âœ— FAIL: Only found {si_overlap} of paper's key S-inhibition heads\")\n",
    "    validation_report.append({\"test\": \"S-Inhibition Discovery\", \"status\": \"FAIL\", \"value\": f\"{si_overlap}/{len(paper_s_inhibition)}\"})\n",
    "\n",
    "# Check duplicate token heads are in early layers\n",
    "dup_in_early = sum(1 for layer, head in duplicate_heads if layer <= 3)\n",
    "print(f\"\\nDuplicate Token Heads:\")\n",
    "print(f\"   We found: {sorted(duplicate_heads)}\")\n",
    "print(f\"   In early layers (0-3): {dup_in_early}/{len(duplicate_heads)}\")\n",
    "if dup_in_early >= len(duplicate_heads) * 0.6:\n",
    "    print(f\"   âœ“ PASS: Most duplicate token heads are in early layers\")\n",
    "    validation_report.append({\"test\": \"Duplicate Head Layers\", \"status\": \"PASS\", \"value\": f\"{dup_in_early}/{len(duplicate_heads)}\"})\n",
    "else:\n",
    "    print(f\"   âœ— FAIL: Not enough duplicate token heads in early layers\")\n",
    "    validation_report.append({\"test\": \"Duplicate Head Layers\", \"status\": \"FAIL\", \"value\": f\"{dup_in_early}/{len(duplicate_heads)}\"})\n",
    "\n",
    "print(\"\\nâœ“ Phase 4 complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 5: Path Patching Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PHASE 5: PATH PATCHING ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len(duplicate_heads) > 0 and len(s_inhibition_heads) > 0 and len(name_mover_heads) > 0:\n",
    "    print(\"\\nAnalyzing paths between circuit components...\")\n",
    "    \n",
    "    path_results = analyze_ioi_circuit_paths(\n",
    "        model,\n",
    "        clean_tokens,\n",
    "        corrupted_tokens,\n",
    "        duplicate_heads[:3],  # Use top 3 of each type\n",
    "        s_inhibition_heads[:3],\n",
    "        name_mover_heads[:3],\n",
    "        io_token_id,\n",
    "        s_token_id\n",
    "    )\n",
    "    \n",
    "    # Analyze duplicate â†’ S-inhibition paths\n",
    "    print(\"\\n1. Duplicate Token â†’ S-Inhibition Paths:\")\n",
    "    dup_to_si = path_results[\"dup_to_s_inhibition\"][\"effect_matrix\"]\n",
    "    max_dup_si = np.max(dup_to_si)\n",
    "    print(f\"   Max effect: {max_dup_si:.3f}\")\n",
    "    print(f\"   Mean effect: {np.mean(dup_to_si):.3f}\")\n",
    "    \n",
    "    # Analyze S-inhibition â†’ Name mover paths\n",
    "    print(\"\\n2. S-Inhibition â†’ Name Mover Paths:\")\n",
    "    si_to_nm = path_results[\"s_inhibition_to_name_mover\"][\"effect_matrix\"]\n",
    "    max_si_nm = np.max(si_to_nm)\n",
    "    print(f\"   Max effect: {max_si_nm:.3f}\")\n",
    "    print(f\"   Mean effect: {np.mean(si_to_nm):.3f}\")\n",
    "    \n",
    "    # Analyze duplicate â†’ Name mover paths\n",
    "    print(\"\\n3. Duplicate Token â†’ Name Mover Paths:\")\n",
    "    dup_to_nm = path_results[\"dup_to_name_mover\"][\"effect_matrix\"]\n",
    "    max_dup_nm = np.max(dup_to_nm)\n",
    "    print(f\"   Max effect: {max_dup_nm:.3f}\")\n",
    "    print(f\"   Mean effect: {np.mean(dup_to_nm):.3f}\")\n",
    "    \n",
    "    print(\"\\nðŸ“Š VALIDATION CHECK 3: Path Importance\")\n",
    "    if max_si_nm > 0.3:\n",
    "        print(f\"   âœ“ PASS: Found strong S-Inhibition â†’ Name Mover path ({max_si_nm:.3f})\")\n",
    "        validation_report.append({\"test\": \"SIâ†’NM Path\", \"status\": \"PASS\", \"value\": f\"{max_si_nm:.3f}\"})\n",
    "    else:\n",
    "        print(f\"   âœ— FAIL: No strong S-Inhibition â†’ Name Mover path\")\n",
    "        validation_report.append({\"test\": \"SIâ†’NM Path\", \"status\": \"FAIL\", \"value\": f\"{max_si_nm:.3f}\"})\n",
    "else:\n",
    "    print(\"\\nâš  Skipping path patching - insufficient heads discovered\")\n",
    "    validation_report.append({\"test\": \"Path Patching\", \"status\": \"SKIP\", \"value\": \"Insufficient heads\"})\n",
    "\n",
    "print(\"\\nâœ“ Phase 5 complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 6: Complete Circuit Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PHASE 6: COMPLETE CIRCUIT DISCOVERY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nRunning complete circuit discovery pipeline...\")\n",
    "print(\"(This combines attention patterns + activation patching + path patching)\\n\")\n",
    "\n",
    "discovered_circuit = discover_ioi_circuit(\n",
    "    model,\n",
    "    \"../data/ioi_abba.json\",\n",
    "    max_examples=30,\n",
    "    head_threshold=0.35,\n",
    "    path_threshold=0.25\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "print_circuit_summary(discovered_circuit)\n",
    "\n",
    "# Save circuit\n",
    "circuit_path = \"../results/discovered_ioi_circuit.json\"\n",
    "with open(circuit_path, 'w') as f:\n",
    "    # Convert tuples to lists for JSON serialization\n",
    "    json_circuit = {\n",
    "        \"duplicate_token_heads\": [list(h) for h in discovered_circuit[\"duplicate_token_heads\"]],\n",
    "        \"s_inhibition_heads\": [list(h) for h in discovered_circuit[\"s_inhibition_heads\"]],\n",
    "        \"name_mover_heads\": [list(h) for h in discovered_circuit[\"name_mover_heads\"]],\n",
    "        \"critical_paths\": [\n",
    "            {**p, \"from\": list(p[\"from\"]), \"to\": list(p[\"to\"])}\n",
    "            for p in discovered_circuit[\"critical_paths\"]\n",
    "        ],\n",
    "        \"head_effects\": discovered_circuit[\"head_effects\"],\n",
    "        \"metadata\": discovered_circuit[\"metadata\"]\n",
    "    }\n",
    "    json.dump(json_circuit, f, indent=2)\n",
    "print(f\"\\nðŸ’¾ Saved circuit to {circuit_path}\")\n",
    "\n",
    "# Validate circuit\n",
    "print(\"\\nValidating discovered circuit...\")\n",
    "validation_results = validate_circuit(\n",
    "    model,\n",
    "    \"../data/ioi_abba.json\",\n",
    "    discovered_circuit,\n",
    "    max_examples=50\n",
    ")\n",
    "\n",
    "print(\"\\nâœ“ Phase 6 complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 7: Direct Logit Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PHASE 7: DIRECT LOGIT ATTRIBUTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nComputing direct logit attribution for IO vs S tokens...\")\n",
    "\n",
    "# Use the same example from before\n",
    "print(f\"\\nPrompt: {clean_prompt}\")\n",
    "print(f\"IO token: {example['io_name']}\")\n",
    "print(f\"S token: {example['s_name']}\")\n",
    "\n",
    "# Compare IO vs S attribution\n",
    "comparison = compare_io_vs_s_attribution(\n",
    "    model,\n",
    "    clean_tokens,\n",
    "    io_token_id,\n",
    "    s_token_id\n",
    ")\n",
    "\n",
    "print(f\"\\nLogit difference (IO - S): {comparison['logit_diff']:.3f}\")\n",
    "\n",
    "# Show top contributors\n",
    "print(\"\\nTop 5 heads contributing to IO token:\")\n",
    "for layer, head, contrib in comparison[\"top_io_heads\"][:5]:\n",
    "    print(f\"   L{layer}H{head}: {contrib:6.3f}\")\n",
    "\n",
    "print(\"\\nTop 5 heads suppressing S token:\")\n",
    "for layer, head, contrib in comparison[\"top_s_suppression_heads\"][:5]:\n",
    "    print(f\"   L{layer}H{head}: {contrib:6.3f}\")\n",
    "\n",
    "# Create visualization\n",
    "plot_logit_attribution(\n",
    "    comparison,\n",
    "    save_path=\"../results/logit_attribution.png\",\n",
    "    top_n=15\n",
    ")\n",
    "\n",
    "# Analyze circuit with DLA\n",
    "print(\"\\nAnalyzing circuit with Direct Logit Attribution...\")\n",
    "dla_analysis = analyze_circuit_with_dla(\n",
    "    model,\n",
    "    clean_tokens,\n",
    "    io_token_id,\n",
    "    s_token_id,\n",
    "    circuit_heads=discovered_circuit\n",
    ")\n",
    "\n",
    "circuit_percentage = dla_analysis[\"circuit_analysis\"][\"circuit_percentage\"]\n",
    "\n",
    "print(\"\\nðŸ“Š VALIDATION CHECK 4: Circuit Attribution\")\n",
    "if circuit_percentage >= 0.60:\n",
    "    print(f\"   âœ“ PASS: Circuit accounts for {circuit_percentage:.1%} of logit diff (â‰¥60%)\")\n",
    "    validation_report.append({\"test\": \"Circuit Attribution\", \"status\": \"PASS\", \"value\": f\"{circuit_percentage:.1%}\"})\n",
    "else:\n",
    "    print(f\"   âœ— FAIL: Circuit only accounts for {circuit_percentage:.1%} of logit diff\")\n",
    "    validation_report.append({\"test\": \"Circuit Attribution\", \"status\": \"FAIL\", \"value\": f\"{circuit_percentage:.1%}\"})\n",
    "\n",
    "print(\"\\nâœ“ Phase 7 complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Final Validation Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"FINAL VALIDATION REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create report dataframe\n",
    "report_df = pd.DataFrame(validation_report)\n",
    "\n",
    "# Display report\n",
    "print(\"\\n\")\n",
    "print(report_df.to_string(index=False))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Count results\n",
    "n_pass = sum(1 for r in validation_report if r[\"status\"] == \"PASS\")\n",
    "n_fail = sum(1 for r in validation_report if r[\"status\"] == \"FAIL\")\n",
    "n_skip = sum(1 for r in validation_report if r[\"status\"] == \"SKIP\")\n",
    "n_total = len(validation_report)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"RESULTS: {n_pass} PASS | {n_fail} FAIL | {n_skip} SKIP | {n_total} TOTAL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Overall assessment\n",
    "pass_rate = n_pass / max(n_total - n_skip, 1)\n",
    "\n",
    "print(\"\\nðŸ“Š OVERALL ASSESSMENT:\\n\")\n",
    "if pass_rate >= 0.8:\n",
    "    print(\"âœ… EXCELLENT: Our implementation successfully replicates the IOI circuit!\")\n",
    "    print(\"   The discovered circuit matches the paper's key findings.\")\n",
    "elif pass_rate >= 0.6:\n",
    "    print(\"âœ“ GOOD: Our implementation largely replicates the IOI circuit.\")\n",
    "    print(\"   Some minor discrepancies exist but overall structure is correct.\")\n",
    "elif pass_rate >= 0.4:\n",
    "    print(\"âš  PARTIAL: Our implementation partially replicates the IOI circuit.\")\n",
    "    print(\"   Significant discrepancies exist. Further investigation needed.\")\n",
    "else:\n",
    "    print(\"âŒ POOR: Our implementation does not match the paper's findings.\")\n",
    "    print(\"   Major issues detected. Review implementation carefully.\")\n",
    "\n",
    "# Save report\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "report_path = f\"../results/validation_report_{timestamp}.csv\"\n",
    "report_df.to_csv(report_path, index=False)\n",
    "print(f\"\\nðŸ’¾ Saved detailed report to {report_path}\")\n",
    "\n",
    "# Create summary document\n",
    "summary_path = f\"../results/validation_summary_{timestamp}.txt\"\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(\"IOI CIRCUIT REPLICATION VALIDATION SUMMARY\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"Model: GPT-2 Small\\n\")\n",
    "    f.write(f\"Device: {device}\\n\\n\")\n",
    "    \n",
    "    f.write(\"BASELINE PERFORMANCE\\n\")\n",
    "    f.write(\"-\" * 40 + \"\\n\")\n",
    "    f.write(f\"Accuracy: {accuracy:.1%}\\n\")\n",
    "    f.write(f\"Mean Logit Diff: {mean_logit_diff:.3f} Â± {std_logit_diff:.3f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"DISCOVERED CIRCUIT\\n\")\n",
    "    f.write(\"-\" * 40 + \"\\n\")\n",
    "    f.write(f\"Duplicate Token Heads: {len(discovered_circuit['duplicate_token_heads'])}\\n\")\n",
    "    f.write(f\"S-Inhibition Heads: {len(discovered_circuit['s_inhibition_heads'])}\\n\")\n",
    "    f.write(f\"Name Mover Heads: {len(discovered_circuit['name_mover_heads'])}\\n\")\n",
    "    f.write(f\"Critical Paths: {len(discovered_circuit['critical_paths'])}\\n\\n\")\n",
    "    \n",
    "    f.write(\"VALIDATION RESULTS\\n\")\n",
    "    f.write(\"-\" * 40 + \"\\n\")\n",
    "    f.write(report_df.to_string(index=False))\n",
    "    f.write(\"\\n\\n\")\n",
    "    \n",
    "    f.write(f\"SUMMARY: {n_pass} PASS | {n_fail} FAIL | {n_skip} SKIP\\n\")\n",
    "    f.write(f\"Pass Rate: {pass_rate:.1%}\\n\")\n",
    "\n",
    "print(f\"ðŸ’¾ Saved summary to {summary_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ“ VALIDATION COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Key Findings Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"KEY FINDINGS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. BASELINE PERFORMANCE\")\n",
    "print(f\"   - Model accuracy: {accuracy:.1%}\")\n",
    "print(f\"   - Mean logit difference: {mean_logit_diff:.3f}\")\n",
    "print(f\"   - Paper expectation: ~95% accuracy, positive logit diff\")\n",
    "\n",
    "print(\"\\n2. CIRCUIT COMPONENTS\")\n",
    "print(f\"   - Duplicate Token Heads: {sorted(discovered_circuit['duplicate_token_heads'])}\")\n",
    "print(f\"   - S-Inhibition Heads: {sorted(discovered_circuit['s_inhibition_heads'])}\")\n",
    "print(f\"   - Name Mover Heads: {sorted(discovered_circuit['name_mover_heads'])}\")\n",
    "\n",
    "print(\"\\n3. CIRCUIT VALIDATION\")\n",
    "if \"circuit_analysis\" in dla_analysis:\n",
    "    print(f\"   - Circuit logit diff contribution: {dla_analysis['circuit_analysis']['circuit_logit_diff']:.3f}\")\n",
    "    print(f\"   - Total logit diff: {dla_analysis['circuit_analysis']['total_logit_diff']:.3f}\")\n",
    "    print(f\"   - Circuit percentage: {dla_analysis['circuit_analysis']['circuit_percentage']:.1%}\")\n",
    "    print(f\"   - Paper expectation: 80-95% from circuit heads\")\n",
    "\n",
    "print(\"\\n4. COMPARISON WITH PAPER\")\n",
    "print(f\"   - Name mover overlap: {nm_overlap}/{len(paper_name_movers)} key heads\")\n",
    "print(f\"   - S-inhibition overlap: {si_overlap}/{len(paper_s_inhibition)} key heads\")\n",
    "print(f\"   - Overall validation: {n_pass}/{n_total - n_skip} checks passed\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Notes and Observations\n",
    "\n",
    "### Expected Behavior:\n",
    "1. The model should achieve >90% accuracy on IOI task\n",
    "2. Circuit heads should be concentrated in expected layers:\n",
    "   - Duplicate token heads: Early layers (0-3)\n",
    "   - S-inhibition heads: Middle layers (7-8)\n",
    "   - Name mover heads: Late layers (9-11)\n",
    "3. Circuit heads should account for majority (>60%) of logit difference\n",
    "\n",
    "### Potential Discrepancies:\n",
    "- Exact heads may vary slightly depending on dataset and thresholds\n",
    "- Some heads may have borderline effects and be included/excluded based on threshold\n",
    "- Path effects can be noisy on single examples\n",
    "\n",
    "### Next Steps:\n",
    "1. If validation fails: Try different thresholds or more examples\n",
    "2. Analyze specific discrepancies in detail\n",
    "3. Consider running on additional dataset templates\n",
    "4. Compare attention patterns qualitatively\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
